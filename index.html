<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sungmin Woo</title>
  
  <meta name="author" content="Sungmin Woo">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sungmin Woo</name>
              </p>
              <p>
                I am a Ph.D candidate at <a href="https://www.yonsei.ac.kr">Yonsei University</a>, Seoul, Korea.
              </p>
              <p>
                My research mainly focuses on 3D computer vision tasks such as depth estimation, point cloud processing, neural rendering, and motion prediction.
              </p>
              <p>
                Please feel free to contact me if you have any questions or suggestions :)
              </p>
              <!-- <p>
                I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p> -->
              <p style="text-align:center">
                <a href="mailto:smw3250@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/resume/sungminwoo-resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=q1BRGh0AAAAJ&hl=ko">Google Scholar</a> &nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile/sungminwoo.png">
            </td>
          </tr>
        </tbody></table>

<!-- =================== Experience =================== -->
<table width="35%" align="center" style="margin-left:10px" cellspacing="0" cellpadding="0" border="0">
  <tr>
    <th width="16%" valign="top" align="center">
      <img src="images/exp/download.png" alt="sym" width="40%"></a>
      <p style="line-height:1.3; font-size:9pt">Yonsei University<br>B.S in EE<br>Mar. 16 - Feb. 20</p>
    </th>
    <th width="16%" valign="top" align="center">
      <img src="images/exp/download.png" alt="sym" width="40%"></a>
      <p style="line-height:1.3; font-size:9pt">Yonsei University<br>Ph.D in EE<br>Mar. 20 - Feb. 25</p>
    </th>
  </tr>
</table>
	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publication</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<tr onmouseout="pcvr_stop()" onmouseover="pcvr_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='pcvr_image'>
        <img src='images/prodepth/prodepth_after.png' width="160">
      </div>
      <img src='images/prodepth/prodepth_before.png' width="160">
    </div>
    <script type="text/javascript">
      function pcvr_start() {
        document.getElementById('pcvr_image').style.opacity = "1";
      }

      function pcvr_stop() {
        document.getElementById('pcvr_image').style.opacity = "0";
      }
      pcvr_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <!-- <a href="https://arxiv.org/pdf/2311.17952.pdf"> -->
      <papertitle>ProDepth: Boosting Self-Supervised Multi-Frame Monocular Depth with Probabilistic Fusion</papertitle>
    <!-- </a> -->
    <br>
    <strong>Sungmin Woo*</strong>,
    Wonjoon Lee*,
    Woojin Kim,
    Dogyoon Lee,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>European Conference on Computer Vision (ECCV) </em>, 2024 
    <br>
    <!-- <a href="https://arxiv.org/pdf/2311.17952.pdf">Paper</a>
    /
    <a href="https://github.com/Hydragon516/SVL">arXiv</a>
    /
    <a href="data/bib/svl2024.txt">Code</a> -->
    Paper
    /
    Arxiv
    /
    Code
    / Project Page
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel framework called ProDepth, which effectively addresses the mismatch problem caused by dynamic objects using a probabilistic approach.
    </p>
  </td>
</tr>

<tr onmouseout="gsa_stop()" onmouseover="gsa_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='gsa_image'>
        <img src='images/fimp/fimp_after.png' width="160">
      </div>
      <img src='images/fimp/fimp_before.png' width="160">
    </div>
    <script type="text/javascript">
      function gsa_start() {
        document.getElementById('gsa_image').style.opacity = "1";
      }

      function gsa_stop() {
        document.getElementById('gsa_image').style.opacity = "0";
      }
      gsa_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2401.16189">
      <papertitle>FIMP: Future Interaction Modeling for Multi-Agent Motion Prediction</papertitle>
    </a>
    <br>
    <strong>Sungmin Woo</strong>,
    Minjung Kim,
    Donghyeong Kim,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2024 
    <br>
    Paper
    /
    <a href="https://arxiv.org/pdf/2401.16189">arXiv</a>
    /
    Code
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose Future Interaction modeling for Motion Prediction (FIMP), which captures potential future interactions in an endto-end manner.
    </p>
  </td>
</tr>


<tr onmouseout="mkconv_stop()" onmouseover="mkconv_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='mkconv_image'>
        <img src='images/mkconv/mkconv_after.png' width="160"></div>
      <img src='images/mkconv/mkconv_before.png' width="160">
    </div>
    <script type="text/javascript">
      function mkconv_start() {
        document.getElementById('mkconv_image').style.opacity = "1";
      }

      function mkconv_stop() {
        document.getElementById('mkconv_image').style.opacity = "0";
      }
      mkconv_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://www.sciencedirect.com/science/article/pii/S0031320323004983">
      <papertitle>MKConv: Multidimensional Feature Representation for Point Cloud Analysis</papertitle>
    </a>
    <br>
    <strong>Sungmin Woo</strong>,
    Dogyoon Lee,
    Sangwon Hwang,
    Woojin Kim,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>Pattern Recognition (PR)</em>, 2023
    <br>
    <a href="https://www.sciencedirect.com/science/article/pii/S0031320323004983">Paper</a>
    /
    <a href="https://arxiv.org/pdf/2107.12655">arXiv</a>
    /
    Code
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel convolution operation for point cloud processing, introducing a multidimensional feature representation.
    </p>
  </td>
</tr>

		
<tr onmouseout="robustlane_stop()" onmouseover="robustlane_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='robust_lane_image'>
        <img src='images/stc/stc_after.png' width="160"></div>
      <img src='images/stc/stc_before.png' width="160">
    </div>
    <script type="text/javascript">
      function robustlane_start() {
        document.getElementById('robust_lane_image').style.opacity = "1";
      }

      function robustlane_stop() {
        document.getElementById('robust_lane_image').style.opacity = "0";
      }
      robustlane_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Leveraging_Spatio-Temporal_Dependency_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf">
      <papertitle>Leveraging Spatio-Temporal Dependency for Skeleton-Based Action Recognition</papertitle>
    </a>
    <br>
    Jungho Lee,
    Minhyeok Lee,
    Suhwan Cho,
    <strong>Sungmin Woo</strong>,
    Sungjun Jang,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023
    <br>
    <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Leveraging_Spatio-Temporal_Dependency_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf">Paper</a>
    /
    <a href="https://arxiv.org/pdf/2212.04761">arXiv</a>
    /
    <a href="https://github.com/Jho-Yonsei/STC-Net/">Code</a>
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel Spatio-Temporal Curve Network (STC-Net) for skeleton-based action recognition, which consists of spatial modules with an spatio-temporal curve (STC) module and graph convolution with dilated kernels.
    </p>
  </td>
</tr>

<tr onmouseout="fpr_stop()" onmouseover="fpr_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='fpr_image'>
        <img src='images/msv/msv_after.png' width="160"></div>
      <img src='images/msv/msv_before.png' width="160">
    </div>
    <script type="text/javascript">
      function fpr_start() {
        document.getElementById('fpr_image').style.opacity = "1";
      }

      function fpr_stop() {
        document.getElementById('fpr_image').style.opacity = "0";
      }
      fpr_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10222443">
      <papertitle>MSV-RGNN: Multiscale Voxel Graph Neural Network for 3D Object Detection</papertitle>
    </a>
    <br>
    Wonjoon Lee,
    <strong>Sungmin Woo</strong>,
    Donghyeong Kim,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Image Processing (ICIP)</em>, 2023
    <br>
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10222443">Paper</a>
    /
    arXiv
    /
    Code
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose MSV-RGNN, a two-stage 3D object detector that utilizes multiple sets of graphs across all scales via a multiscale-voxel-graph RoI pooling module.
    </p>
  </td>
</tr>

<tr onmouseout="margin_stop()" onmouseover="margin_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='margin_image'>
        <img src='images/margin/margin_after.png' width="160"></div>
      <img src='images/margin/margin_before.png' width="160">
    </div>
    <script type="text/javascript">
      function margin_start() {
        document.getElementById('margin_image').style.opacity = "1";
      }

      function margin_stop() {
        document.getElementById('margin_image').style.opacity = "0";
      }
      margin_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9898030">
      <papertitle>Detection-Identification Balancing Margin Loss for One-Stage Multi-Object Tracking</papertitle>
    </a>
    <br>
    Heansung Lee, 
    Suhwan Cho, 
    Sungjun Jang,
    Jungho Lee,
    <strong>Sungmin Woo</strong>,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Image Processing (ICIP)</em>, 2022
    <br>
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9898030">Paper</a>
    /
    arXiv
    /
    Code
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We present a Detection-Identification balancing Margin loss on one-stage MOT for suppressing negative transfer effect to achieve balanced performance of detection and re-ID.
    </p>
  </td>
</tr>

<tr onmouseout="rsmix_stop()" onmouseover="rsmix_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='rsmix_image'>
        <img src='images/rsmix/rsmix_after.png' width="160"></div>
      <img src='images/rsmix/rsmix_before.png' width="160">
    </div>
    <script type="text/javascript">
      function rsmix_start() {
        document.getElementById('rsmix_image').style.opacity = "1";
      }

      function rsmix_stop() {
        document.getElementById('rsmix_image').style.opacity = "0";
      }
      rsmix_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">
      <papertitle>Regularization Strategy for Point Cloud via Rigidly Mixed Sample</papertitle>
    </a>
    <br>
    Dogyoon Lee,
    Jaeha Lee,
    Junhyeop Lee,
    Hyeongmin Lee,
    Minhyeok Lee,
    <strong>Sungmin Woo</strong>,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE/CVF Computer Vision and Pattern Recognition (CVPR)</em>, 2021 
    <br>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">Paper</a>
    /
    <a href="https://arxiv.org/pdf/2102.01929">arXiv</a>
    /
    <a href="https://github.com/dogyoonlee/RSMix">Code</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel data augmentation method called Rigid Subset Mix (RSMix) which generates virtual mixed samples by replacing part of the sample with shape-preserved subsets from another sample.
    </p>
  </td>
</tr>

<tr onmouseout="depthedge_stop()" onmouseover="depthedge_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='depthedge_image'>
        <img src='images/depthedge/depthedge_after.png' width="160"></div>
      <img src='images/depthedge/depthedge_before.png' width="160">
    </div>
    <script type="text/javascript">
      function depthedge_start() {
        document.getElementById('depthedge_image').style.opacity = "1";
      }

      function depthedge_stop() {
        document.getElementById('depthedge_image').style.opacity = "0";
      }
      depthedge_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9635718">
      <papertitle>Lidar depth completion using color-embedded information via knowledge distillation</papertitle>
    </a>
    <br>
    Sangwon Hwang,
    Junhyeop Lee,
    Woojin Kim,
    <strong>Sungmin Woo</strong>,
    Kyungjae Lee,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE Transactions on Intelligent Transportation Systems (T-ITS)</em>, 2021 
    <br>
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9635718">Paper</a>
    /
    arXiv
    /
    Code
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We present a depth completion framework consisting of depth and edge CNNs with transferring of knowledge.
    </p>
  </td>
</tr>

<tr onmouseout="aibm_stop()" onmouseover="aibm_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='aibm_image'>
        <img src='images/aibm/aibm_after.png' width="160"></div>
      <img src='images/aibm/aibm_before.png' width="160">
    </div>
    <script type="text/javascript">
      function aibm_start() {
        document.getElementById('aibm_image').style.opacity = "1";
      }

      function aibm_stop() {
        document.getElementById('aibm_image').style.opacity = "0";
      }
      aibm_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9468367">
      <papertitle>AIBM: Accurate and instant background modeling for moving object detection</papertitle>
    </a>
    <br>
    Woojin Kim,
    Sangwon Hwang,
    Junhyeop Lee,
    <strong>Sungmin Woo</strong>,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE Transactions on Intelligent Transportation Systems (T-ITS)</em>, 2021 
    <br>
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9468367">Paper</a>
    /
    arXiv
    /
    Code
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel background modeling method for moving object detection based on inpainting and enhancing the resolution using a coarse-to-fine strategy.
    </p>
  </td>
</tr>

<tr onmouseout="ghost_stop()" onmouseover="ghost_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='ghost_image'>
        <img src='images/ghost/ghost_after.png' width="160"></div>
      <img src='images/ghost/ghost_before.png' width="160">
    </div>
    <script type="text/javascript">
      function ghost_start() {
        document.getElementById('ghost_image').style.opacity = "1";
      }

      function ghost_stop() {
        document.getElementById('ghost_image').style.opacity = "0";
      }
      ghost_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9641919">
      <papertitle>Ghost graph convolutional network for skeleton-based action recognition</papertitle>
    </a>
    <br>
    Sungjun Jang,
    Heansung Lee,
    Suhwan Cho,
    <strong>Sungmin Woo</strong>,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia))</em>, 2021 
    <br>
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9641919">Paper</a>
    /
    arXiv
    /
    Code
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a ghost graph convolution for skeleton-based action recognition.
    </p>
  </td>
</tr>

<tr onmouseout="false_stop()" onmouseover="false_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='false_image'>
        <img src='images/false/false_after.png' width="160"></div>
      <img src='images/false/false_before.png' width="160">
    </div>
    <script type="text/javascript">
      function false_start() {
        document.getElementById('false_image').style.opacity = "1";
      }

      function false_stop() {
        document.getElementById('false_image').style.opacity = "0";
      }
      false_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9190808">
      <papertitle>False Positive Removal For 3D Vehicle Detection with Penetrated Point Classifier</papertitle>
    </a>
    <br>
    <strong>Sungmin Woo</strong>,
    Sangwon Hwang,
    Woojin Kim,
    Junhyeop Lee,
    Dogyoon Lee,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Image Processing (ICIP)</em>, 2020
    <br>
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9190808">Paper</a>
    /
    <a href="https://arxiv.org/pdf/2005.13153">arXiv</a>
    /
    Code
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel post-processing method to remove false positives in 3D vehicle detection utilizing the characteristics of the LiDAR sensor itself.
    </p>
  </td>
</tr>

</tbody></table>

				
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td>
          <heading>Preprint</heading>
        </td>
      </tr>
    </tbody>
  </table>
  

      <!-- <tr>
        <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/cvf.jpg">
        </td>
        <td width="75%" valign="center">
          <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
          <br>
          <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
          <br>
          <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
          <br>
          <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
        </td>
      </tr>
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/cs188.jpg" alt="cs188">
        </td>
        <td width="75%" valign="center">
          <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
          <br>
          <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
          <br>
          <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
        </td>
      </tr>
      

      <tr>
        <td align="center" style="padding:20px;width:25%;vertical-align:middle">
          <heading>Basically <br> Blog Posts</heading>
        </td>
        <td width="75%" valign="middle">
          <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
          <br>
          <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
          <br>
          <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
        </td>
      </tr>
        -->	
    </tbody>
  </table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
            This website's source code is borrowed from <a href="https://github.com/jonbarron/jonbarron_website">jonbarron's website</a>.
          </p>
          <p style="text-align:right;font-size:small;">
            Last updated July 2024.
          </p>
        </td>
      </tr>
    </tbody>
  </table>
  <!-- </td>
  </tr> -->
<!-- </table> -->
</body>

</html>
